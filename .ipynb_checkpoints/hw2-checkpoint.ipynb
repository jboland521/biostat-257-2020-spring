{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIOSTAT 257 Homework 2\n",
    "\n",
    "Consider a linear mixed effects model\n",
    "\n",
    "$$Y_i = X_i\\beta + Z_i\\gamma + \\epsilon_i, \\quad i = 1,\\ldots,n$$\n",
    "\n",
    "where\n",
    "\n",
    "- $Y_i \\in \\mathbb{R}^{n_i}$ is the reponse vector of the $i$-th individual,\n",
    "- $X_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effect predictor matrix of  $i$-th individual,\n",
    "- $Z_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effect predictor matrix of  $i$-th individual, \n",
    "- $\\epsilon_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(0_{n_i}, \\sigma^2 I_{n_i})$,\n",
    "- $\\beta \\in \\mathbb{R}^{p}$ are fixed effects, and\n",
    "- $\\gamma \\in \\mathbb{R}^{q}$ are random effects assumed to be $N(0_{q}, \\Sigma_{q \\times q})$ independent of $\\epsilon_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Formula\n",
    "\n",
    "Write down the log-likelihood of the  $i$-th datum  $(Y_i,X_i,Z_i)$  given parameters $(\\beta,\\Sigma,\\sigma^2)$.\n",
    "\n",
    "The marginal distribution of $Y_i \\sim N(X_i \\beta, Z_i \\Sigma Z_i^T + \\sigma^2 I_{n_i})$\n",
    "\n",
    "$$\\ell(\\beta,\\Sigma,\\sigma^2) = -\\frac{n_i}{2}\\text{log}(2\\pi) - \\frac{1}{2}\\text{log}|Z_i \\Sigma Z_i^T + \\sigma^2 I_{n_i}| - \\frac{1}{2}(Y_i - X_i \\beta)^T(Z_i \\Sigma Z_i^T + \\sigma^2 I_{n_i})^{-1}(Y_i - X_i \\beta)$$\n",
    "\n",
    "The most computationally challenging terms will be the log determinant and the matrix inversion. First we know that $\\Sigma = L L'$. We can write \n",
    "\n",
    "$$Z\\Sigma Z^T = Z L L^T Z^T = (ZL)(ZL)^T = RR^T$$\n",
    "\n",
    "We can use Woodbury to rewrite the covariance matrix as:\n",
    "\n",
    "$$(RR^T + \\sigma^2 I_{n_i})^{-1} = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}R\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg)^{-1}R^T.$$\n",
    "\n",
    "Then, the quadratic form then becomes: \n",
    "\n",
    "$$\\frac{1}{\\sigma^2}(y-X\\beta)^T(y-X\\beta) -\\frac{1}{\\sigma^4}(y-X\\beta)^TR\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg)^{-1}R^T(y-X\\beta)$$\n",
    "\n",
    "where if we let $C = R^T(y-X\\beta) = L^TZ^T(y-X\\beta)$, this then becomes:\n",
    "\n",
    "$$\\frac{1}{\\sigma^2}(y-X\\beta)^T(y-X\\beta) -\\frac{1}{\\sigma^4}C^T\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg)^{-1}C$$\n",
    "\n",
    "$$I + \\frac{1}{\\sigma^2}R^TR = MM^T.$$\n",
    "\n",
    "Which leads us to: \n",
    "\n",
    "$$(RR^T + \\sigma^2 I_{n_i})^{-1} = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}R\\Bigg(MM^T\\Bigg)^{-1}R^T = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}RM^{-T}M^{-1}R^T$$\n",
    "\n",
    "\n",
    "$$(RR^T + \\sigma^2 I_{n_i})^{-1} = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}Q^TQ$$\n",
    "\n",
    "such that $M^{-1}R^T = Q$. If we let $e = y - X \\beta$, then we can write the quadratic form as:\n",
    "\n",
    "$$e^T(\\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}Q^TQ)e = \\frac{1}{\\sigma^2}e^Te - \\frac{1}{\\sigma^4} e^TQ^TQe$$\n",
    "\n",
    "The other difficult term to work with is \n",
    "\n",
    "$$\\text{det}(\\sigma^2I + Z\\Sigma Z^T) = \\text{det}(\\sigma^2I)\\text{det}\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg) = (\\sigma^2)^n\\text{det}(MM^T)$$\n",
    "\n",
    "Thus we can re-write the log-likelihood as\n",
    "\n",
    "$$\\ell(\\beta,\\Sigma,\\sigma^2) = -\\frac{n_i}{2}\\text{log}(2\\pi) - \\frac{1}{2}log((\\sigma^2)^n\\text{det}(MM^T)) - \\frac{1}{2\\sigma^2}e^Te + \\frac{1}{2\\sigma^4} e^TQ^TQe$$\n",
    "\n",
    "$$\\ell(\\beta,\\Sigma,\\sigma^2) = -\\frac{n_i}{2}\\text{log}(2\\pi) - \\frac{n_i}{2}log(\\sigma^2) -\\frac{1}{2}log(\\text{det}(MM^T)) - \\frac{1}{2\\sigma^2}e^Te + \\frac{1}{2\\sigma^4} e^TQ^TQe$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Start-up Code\n",
    "\n",
    "Use the following template to define a type `LmmObs` that holds an LMM datum $(y_i,X_i,Z_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Distributions, LinearAlgebra, Random, SparseArrays, InteractiveUtils\n",
    "\n",
    "# define a type that holds LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y :: Vector{T}\n",
    "    X :: Matrix{T}\n",
    "    Z :: Matrix{T}\n",
    "    # working arrays\n",
    "    # whatever intermediate arrays you may want to pre-allocate\n",
    "    res         :: Vector{T}\n",
    "    storage_q   :: Vector{T}\n",
    "    storage_q2  :: Vector{T}\n",
    "    ztz         :: Matrix{T}\n",
    "    storage_qq  :: Matrix{T}\n",
    "    storage_qq2 :: Matrix{T}\n",
    "end\n",
    "\n",
    "# constructor\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}) where T <: AbstractFloat\n",
    "    res         = similar(y)\n",
    "    storage_q   = Vector{T}(undef, size(Z, 2))\n",
    "    storage_q2  = Vector{T}(undef, size(Z, 2))\n",
    "    ztz         = transpose(Z) * Z\n",
    "    storage_qq  = similar(ztz)\n",
    "    storage_qq2 = similar(ztz)\n",
    "    LmmObs(y, X, Z, res, storage_q, storage_q2, ztz, storage_qq, storage_qq2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, with interface `logl!(obs, β, L, σ²)` that evaluates the log-likelihood of the $i$-th datum. Here `L` is the lower triangular Cholesky factor from the Cholesky decomposition `Σ=LL'`. Make your code efficient in the $n_i≫q$ case. Think the intensive longitudinal measurement setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl! (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logl!(\n",
    "        obs :: LmmObs{T}, \n",
    "        β   :: Vector{T}, \n",
    "        L   :: Matrix{T}, \n",
    "        σ²  :: T) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2) \n",
    "    ## Calculate y - Xβ\n",
    "    mul!(obs.res, obs.X, β)\n",
    "    axpy!(-1, obs.y, obs.res)\n",
    "    \n",
    "    ## Start calculating (I + (1/σ^2)R^tR)\n",
    "    mul!(obs.storage_qq, L', obs.ztz)\n",
    "    mul!(obs.storage_qq2, obs.storage_qq, L)\n",
    "    mul!(obs.ztz, obs.storage_qq2, 1/σ²)\n",
    "    for i = 1:q\n",
    "        obs.ztz[i, i] += 1\n",
    "    end\n",
    "    \n",
    "    ## M^-1L^tZ^T(y-Xβ)\n",
    "    mul!(obs.storage_q, obs.Z', obs.res)\n",
    "    mul!(obs.storage_q2, L', obs.storage_q)\n",
    "    \n",
    "    ## Cholesky Decomposition of (I + (1/σ^2)R^tR)\n",
    "    M = cholesky!(Symmetric(obs.ztz))\n",
    "    \n",
    "    return -n / 2 * log(2 * π) - n / 2 * log(σ²) - 1 / 2 * logdet(M) - \n",
    "        1/ (2 * σ²) * dot(obs.res, obs.res) + \n",
    "        1 / (2 * (σ²)^2) * dot(obs.storage_q2, M \\ obs.storage_q2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: This function shouldn't be very long. Mine, obeying 80-character rule, is 25 lines. If you find yourself writing very long code, you're on the wrong track. Think about algorithm first then use BLAS functions to reduce memory allocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Correctness\n",
    "\n",
    "Compare your result (both accuracy and timing) to the Distributions.jl package using following data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs{Float64}([5.739048710854997, 5.705395720270055, 2.7368899643050355, 1.4201223592870755, -0.2099433929180451, 3.5886971824690486, -1.3778538474575956, -0.08406026821055246, -2.208007878450787, 1.309558511583542  …  1.2947876180172684, -1.9701265304395086, -2.040383092851745, -1.4590296825658675, 0.18616271231054726, 1.0681247149968018, 2.2292080864625254, 1.1952385354603545, 1.1310626949609701, -0.43507816286713785], [1.0 -2.506566300781151 … 0.5863780184080776 1.1092991040518192; 1.0 -0.974090320735282 … 1.4143507320583761 0.45608259198567447; … ; 1.0 -1.0076371084863895 … -1.3241972696483915 1.4547609424344008; 1.0 0.38036793320364776 … -0.5857507269707397 1.796804266836504], [1.0 -0.6380567326757537 1.4738982136806946; 1.0 -2.0711110232845926 0.21422658785510312; … ; 1.0 0.5917731507133951 -0.9163364468263059; 1.0 0.9463732120394507 -0.325860403600768], [NaN, 3.544277064e-315, NaN, 3.54421817e-315, NaN, 0.4927720183169773, NaN, 3.544280937e-315, NaN, 3.5442988e-315  …  NaN, 3.544283467e-315, NaN, -0.1160655106162325, NaN, 1.875503912521001, NaN, -0.06813640782610557, NaN, -0.1530748817211443], [1031.1723794716493, 2090.111218822357, -107.38952273743904], [1031.1723794716493, 2090.111218822357, -107.38952273743904], [2000.0 -11.2035856885878 -23.35638533913959; -11.2035856885878 1972.7426082447305 27.303296982632173; -23.35638533913959 27.303296982632173 2034.203494486357], [1.620465517e-315 5.34680292e-316 0.0; 1.62046615e-315 5.34680292e-316 0.0; 1.620467256e-315 5.34680292e-316 0.0], [5.0e-324 5.0e-324 0.0; 5.0e-324 5.0e-324 0.0; 0.0 0.0 0.0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form an LmmObs object\n",
    "obs = LmmObs(y, X, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3247.4568580638297"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Profile\n",
    "@profile logl!(obs, β, Matrix(cholesky(Σ).L), σ²) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: logl!(obs, β, Matrix((cholesky(Σ)).L), σ²) ≈ logpdf(mvn, y)",
     "output_type": "error",
     "traceback": [
      "AssertionError: logl!(obs, β, Matrix((cholesky(Σ)).L), σ²) ≈ logpdf(mvn, y)",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[60]:5"
     ]
    }
   ],
   "source": [
    "μ  = X * β\n",
    "Ω  = Z * Σ * transpose(Z) +  σ² * I\n",
    "mvn = MvNormal(μ, Symmetric(Ω)) # MVN(μ, Σ)\n",
    "logpdf(mvn, y)\n",
    "@assert logl!(obs, β, Matrix(cholesky(Σ).L), σ²) ≈ logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3247.456858063827"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  224 bytes\n",
       "  allocs estimate:  5\n",
       "  --------------\n",
       "  minimum time:     34.800 μs (0.00% GC)\n",
       "  median time:      46.500 μs (0.00% GC)\n",
       "  mean time:        56.155 μs (0.00% GC)\n",
       "  maximum time:     558.401 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = Matrix(cholesky(Σ).L)\n",
    "bm1 = @benchmark logpdf($mvn, $y)\n",
    "bm2 = @benchmark logl!($obs, $β, $L, $σ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.970710322580645"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(median(bm1).time / median(bm2).time / 1000 * 30, 0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.78125"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(30 - median(bm2).memory / 1024, 0, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
