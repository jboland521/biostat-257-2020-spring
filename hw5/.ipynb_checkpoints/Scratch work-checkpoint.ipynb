{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, Distributions, LinearAlgebra, Random, Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # posterior mean and variance of random effects γ\n",
    "    μγ         :: Vector{T} # posterior mean of random effects\n",
    "    νγ         :: Matrix{T} # posterior variance of random effects\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    rtr        :: Vector{T}\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    ztr        :: Vector{T}\n",
    "    ltztr      :: Vector{T}\n",
    "    xtr        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    ltztzl     :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    I3         :: Matrix{T}\n",
    "    Linv       :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "    y::Vector{T}, \n",
    "    X::Matrix{T}, \n",
    "    Z::Matrix{T}) where T <: AbstractFloat\n",
    "    n, p, q = size(X, 1), size(X, 2), size(Z, 2)\n",
    "    μγ         = Vector{T}(undef, q)\n",
    "    νγ         = Matrix{T}(undef, q, q)\n",
    "    yty        = abs2(norm(y))\n",
    "    rtr        = Vector{T}(undef, 1)\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y\n",
    "    ztr        = similar(zty)\n",
    "    ltztr      = similar(zty)\n",
    "    xtr        = Vector{T}(undef, p)\n",
    "    storage_p  = similar(xtr)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    ltztzl     = similar(ztz)\n",
    "    storage_qq = similar(ztz)\n",
    "    I3         = Matrix{T}(I, q, q)\n",
    "    Linv       = Matrix{T}(undef, q, q)\n",
    "    storage_qq2 = Matrix{T}(undef, q, q)\n",
    "    LmmObs(y, X, Z, μγ, νγ, \n",
    "        yty, rtr, xty, zty, ztr, ltztr, xtr,\n",
    "        storage_p, storage_q, \n",
    "        xtx, ztx, ztz, ltztzl, storage_qq, \n",
    "        I3, Linv, storage_qq2)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, β, Σ, L, σ², updater = false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `β`, `Σ`, \n",
    "and `σ²`. The lower triangular Cholesky factor `L` of `Σ` must be supplied too.\n",
    "The fields `obs.μγ` and `obs.νγ` are overwritten by the posterior mean and \n",
    "posterior variance of random effects. If `updater==true`, fields `obs.ztr`, \n",
    "`obs.xtr`, and `obs.rtr` are updated according to input parameter values. \n",
    "Otherwise, it assumes these three fields are pre-computed. \n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs     :: LmmObs{T}, \n",
    "        β       :: Vector{T}, \n",
    "        Σ       :: Matrix{T},\n",
    "        L       :: Matrix{T},\n",
    "        σ²      :: T,\n",
    "        updater :: Bool = false\n",
    "        ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    σ²inv   = inv(σ²)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################\n",
    "    # form the q-by-q matrix: Lt Zt Z L\n",
    "    copy!(obs.ltztzl, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.ltztzl) # O(q^3) obs.ltztzl = Zt Z L\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.ltztzl) # O(q^3) obs.ltztzl = Lt Zt Z L\n",
    "    # form the q-by-q matrix: M = σ² I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ltztzl)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += σ² # obs.storage_qq = σ² I + Lt Zt Z L\n",
    "    end\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3) # obs.storage_qq = Rt\n",
    "    # Zt * res\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.ztx, β, T(1), copy!(obs.ztr, obs.zty)) # O(pq)\n",
    "    # Lt * (Zt * res)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, copy!(obs.ltztr, obs.ztr))    # O(q^2)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, copy!(obs.storage_q, obs.ltztr)) # O(q^3)\n",
    "    # Xt * res = Xt * y - Xt * X * β\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.xtx, β, T(1), copy!(obs.xtr, obs.xty))\n",
    "    # l2 norm of residual vector\n",
    "    updater && (obs.rtr[1] = obs.yty - dot(obs.xty, β) - dot(obs.xtr, β))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2π) + (n - q) * log(σ²) # constant term\n",
    "    @inbounds for j in 1:q # log det term\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (obs.rtr[1] - qf) * σ²inv \n",
    "    logl /= -2\n",
    "    ######################################\n",
    "    # TODO: Evaluate posterior mean and variance\n",
    "    ######################################    \n",
    "    \n",
    "    # Calculate Variance\n",
    "    BLAS.trsm!('R', 'L', 'N', 'N', T(1), L, copy!(obs.Linv, obs.I3)) \n",
    "    BLAS.gemm!('T', 'N', T(1), obs.Linv, obs.Linv, σ²inv, copy!(obs.storage_qq2, obs.ztz))\n",
    "    LAPACK.potrf!('L', obs.storage_qq2)\n",
    "    BLAS.trsm!('R', 'L', 'N', 'N', T(1), obs.storage_qq2, copy!(obs.νγ, obs.I3))\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), obs.νγ, obs.νγ)\n",
    "\n",
    "    # Calculate Expected Value\n",
    "    BLAS.gemv!('N', σ²inv, obs.νγ, obs.ztr, T(0), obs.μγ)\n",
    "    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X = [ones(n) randn(n, p - 1)]\n",
    "Z = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Σ)).L)\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, β, Σ, L, σ², true) = -3247.4568580638243\n",
      "obs.μγ = [-1.7352999248283547, -1.2234665777048983, -0.25020190407763465]\n",
      "obs.νγ = [0.0007495521480103862 4.188026819522356e-6 8.595028349011145e-6; 4.188026819522356e-6 0.0007599372708603274 -1.0092121486077345e-5; 8.595028349011145e-6 -1.0092121486077345e-5 0.0007370698232610101]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, β, Σ, L, σ², true)\n",
    "@show obs.μγ\n",
    "@show obs.νγ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmModel"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat}\n",
    "    # data\n",
    "    data    :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    β       :: Vector{T}\n",
    "    Σ       :: Matrix{T}\n",
    "    L       :: Matrix{T}\n",
    "    σ²      :: Vector{T}    \n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty     :: Vector{T}\n",
    "    xtr     :: Vector{T}\n",
    "    ztr2    :: Vector{T}\n",
    "    xtxinv  :: Matrix{T}\n",
    "    ztz2    :: Matrix{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "        # dims\n",
    "    p      = size(obsvec[1].X, 2)\n",
    "    q      = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    β      = Vector{T}(undef, p)\n",
    "    Σ      = Matrix{T}(undef, q, q)\n",
    "    L      = Matrix{T}(undef, q, q)\n",
    "    σ²     = Vector{T}(undef, 1)    \n",
    "    # intermediate arrays\n",
    "    xty    = zeros(T, p)\n",
    "    xtr    = similar(xty)\n",
    "    ztr2   = Vector{T}(undef, abs2(q))\n",
    "    xtxinv = zeros(T, p, p)\n",
    "    # pre-calculate \\sum_i Xi^T Xi and \\sum_i Xi^T y_i\n",
    "    @inbounds for i in eachindex(obsvec)\n",
    "        obs = obsvec[i]\n",
    "        BLAS.axpy!(T(1), obs.xtx, xtxinv)\n",
    "        BLAS.axpy!(T(1), obs.xty, xty)\n",
    "    end\n",
    "    # invert X'X\n",
    "    LAPACK.potrf!('U', xtxinv)\n",
    "    LAPACK.potri!('U', xtxinv)\n",
    "    LinearAlgebra.copytri!(xtxinv, 'U')\n",
    "    ztz2   = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    storage_p = zeros(T, p)\n",
    "    storage_q = zeros(T, q)\n",
    "    LmmModel(obsvec, β, Σ, L, σ², xty, xtr, ztr2, xtxinv, ztz2, \n",
    "        storage_p, storage_q)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "βtrue  = [0.1; 6.5; -3.5; 1.0; 5]\n",
    "σ²true = 1.5\n",
    "σtrue  = sqrt(σ²true)\n",
    "Σtrue  = Matrix(Diagonal([2.0; 1.2; 1.0]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Σtrue)).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * βtrue .+ Z * (Ltrue * randn(q)) .+ σtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "type Int64 has no field data",
     "output_type": "error",
     "traceback": [
      "type Int64 has no field data",
      "",
      "Stacktrace:",
      " [1] getproperty(::Int64, ::Symbol) at .\\Base.jl:20",
      " [2] top-level scope at .\\In[18]:3"
     ]
    }
   ],
   "source": [
    "@inbounds for i in 1:length(lmm.data)\n",
    "    #logl += logl!(lmm.data[i], lmm.β, lmm.Σ, lmm.L, lmm.σ²[1], true)\n",
    "    BLAS.gemv!('T', 1, m.data[i].ztx, m.data[i].μγ, 1 m.storage_p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    update_em!(m::LmmModel, updater::Bool = false)\n",
    "\n",
    "Perform one iteration of EM update. It returns the log-likelihood calculated \n",
    "from input `m.β`, `m.Σ`, `m.L`, and `m.σ²`. These fields are then overwritten \n",
    "by the next EM iterate. The fields `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` are updated according to the resultant `m.β`. If `updater==true`, \n",
    "the function first updates `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` according to `m.β`. If `updater==false`, it assumes these fields \n",
    "are pre-computed.\n",
    "\"\"\"\n",
    "function update_em!(m::LmmModel{T}, updater::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        logl += logl!(m.data[i], m.β, m.L, m.σ²[1], updater)\n",
    "        BLAS.gemv!('T', T(1), m.data[i].ztx, m.data[i].μγ, T(1), m.xtzμγ)\n",
    "    end\n",
    "    # TODO: update m.β\n",
    "    BLAS.axpy!(T(1), m.xty, m.xtzμγ)\n",
    "    BLAS.gemm!('T', 'N', T(1), m.xtzμγ, m.xtxinv, T(0), m.β)\n",
    "    # TODO: update m.data[i].ztr, m.data[i].xtr, m.data[i].rtr\n",
    "    @inbounds for i in 1:length(m.data) \n",
    "        updater && BLAS.gemv!('N', T(-1), m.data[i].xtx, m.β, T(1), copy!(m.data[i].xtr, m.data[i].xty))\n",
    "        updater && BLAS.gemv!('N', T(-1), m.data[i].ztx,m.β, T(1), copy!(m.data[i].ztr, m.data[i].zty))\n",
    "        updater && (m.data[i].rtr[1] = m.data[i].yty - dot(m.data[i].xty, m.β) - dot(m.data[i].xtr, m.β))\n",
    "    end\n",
    "    # TODO: update m.σ²\n",
    "    nsum = zero(T)\n",
    "    rsum = zero(T)\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        nsum += m.data[i].n\n",
    "        BLAS.gemv!('N', T(1), m.data[i].ztz, m.data[i].μγ, T(0), m.ztzμγ)\n",
    "        BLAS.gemm!('N', 'N', T(1), m.data[i].ztz, m.data[i].νγ, T(0), m.ztzνγ)\n",
    "        rsum += m.data[i].rtr[1] - 2dot(m.data[i].μγ, m.data[i].ztr) + tr(m.ztzνγ) + dot(m.data[i].μγ, m.ztzμγ)\n",
    "    end\n",
    "    # update m.Σ and m.L\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        \n",
    "    end\n",
    "    # return log-likelihood at input parameter values\n",
    "    logl\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
