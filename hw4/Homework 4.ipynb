{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4\n",
    "### BIOSTAT 257\n",
    "### Joanna Boland\n",
    "### May 29, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Derivatives\n",
    "\n",
    "### Question 2: Objective and Gradient Evaluator for a Single Datum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling MixedModels [ff71e718-51f3-5ec2-a782-8ffcbfa3c316]\n",
      "└ @ Base loading.jl:1273\n",
      "ERROR: LoadError: NLopt not installed properly; run Pkg.build(\"NLopt\"), restart Julia, and try again.\n",
      "Stacktrace:\n",
      " [1] error(::String) at .\\error.jl:33\n",
      " [2] top-level scope at C:\\Users\\jbola\\.julia\\packages\\NLopt\\eqN9a\\src\\NLopt.jl:16\n",
      " [3] include at .\\boot.jl:328 [inlined]\n",
      " [4] include_relative(::Module, ::String) at .\\loading.jl:1105\n",
      " [5] include(::Module, ::String) at .\\Base.jl:31\n",
      " [6] top-level scope at none:2\n",
      " [7] eval at .\\boot.jl:330 [inlined]\n",
      " [8] eval(::Expr) at .\\client.jl:425\n",
      " [9] top-level scope at .\\none:3\n",
      "in expression starting at C:\\Users\\jbola\\.julia\\packages\\NLopt\\eqN9a\\src\\NLopt.jl:15\n",
      "ERROR: LoadError: Failed to precompile NLopt [76087f3c-5699-56af-9a33-bf431cd00edd] to C:\\Users\\jbola\\.julia\\compiled\\v1.3\\NLopt\\faRdv_gzmkA.ji.\n",
      "Stacktrace:\n",
      " [1] error(::String) at .\\error.jl:33\n",
      " [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1283\n",
      " [3] _require(::Base.PkgId) at .\\loading.jl:1024\n",
      " [4] require(::Base.PkgId) at .\\loading.jl:922\n",
      " [5] require(::Module, ::Symbol) at .\\loading.jl:917\n",
      " [6] include at .\\boot.jl:328 [inlined]\n",
      " [7] include_relative(::Module, ::String) at .\\loading.jl:1105\n",
      " [8] include(::Module, ::String) at .\\Base.jl:31\n",
      " [9] top-level scope at none:2\n",
      " [10] eval at .\\boot.jl:330 [inlined]\n",
      " [11] eval(::Expr) at .\\client.jl:425\n",
      " [12] top-level scope at .\\none:3\n",
      "in expression starting at C:\\Users\\jbola\\.julia\\packages\\MixedModels\\ALNok\\src\\MixedModels.jl:9\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile MixedModels [ff71e718-51f3-5ec2-a782-8ffcbfa3c316] to C:\\Users\\jbola\\.julia\\compiled\\v1.3\\MixedModels\\tBiYK_gzmkA.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile MixedModels [ff71e718-51f3-5ec2-a782-8ffcbfa3c316] to C:\\Users\\jbola\\.julia\\compiled\\v1.3\\MixedModels\\tBiYK_gzmkA.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at .\\error.jl:33",
      " [2] compilecache(::Base.PkgId, ::String) at .\\loading.jl:1283",
      " [3] _require(::Base.PkgId) at .\\loading.jl:1024",
      " [4] require(::Base.PkgId) at .\\loading.jl:922",
      " [5] require(::Module, ::Symbol) at .\\loading.jl:917",
      " [6] top-level scope at In[2]:3"
     ]
    }
   ],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, CSV, DataFrames, DelimitedFiles, Distributions\n",
    "using Ipopt, LinearAlgebra, MathProgBase, MixedModels\n",
    "using Random, RCall, Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # arrays for holding gradient\n",
    "    ∇β         :: Vector{T}\n",
    "    ∇σ²        :: Vector{T}\n",
    "    ∇Σ         :: Matrix{T}    \n",
    "    # working arrays\n",
    "    # TODO: whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q    = size(X, 1), size(X, 2), size(Z, 2)    \n",
    "    ∇β         = Vector{T}(undef, p)\n",
    "    ∇σ²        = Vector{T}(undef, 1)\n",
    "    ∇Σ         = Matrix{T}(undef, q, q)    \n",
    "    yty        = abs2(norm(y))\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y    \n",
    "    storage_p  = Vector{T}(undef, p)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    storage_qq = similar(ztz)\n",
    "    LmmObs(y, X, Z, ∇β, ∇σ², ∇Σ, \n",
    "        yty, xty, zty, storage_p, storage_q, \n",
    "        xtx, ztx, ztz, storage_qq)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, β, L, σ², needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `β`, `L`, \n",
    "and `σ²`. If `needgrad==true`, then `obs.∇β`, `obs.∇Σ`, and `obs.σ² are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs      :: LmmObs{T}, \n",
    "        β        :: Vector{T}, \n",
    "        L        :: Matrix{T}, \n",
    "        σ²       :: T,\n",
    "        needgrad :: Bool = true\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################    \n",
    "    # form the q-by-q matrix: M = σ² * I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq) # O(q^3)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq) # O(q^3)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += σ²\n",
    "    end\n",
    "    # cholesky on M = σ² * I + Lt Zt Z L\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.gemv!('N', T(-1), obs.ztx, β, T(1), copy!(obs.storage_q, obs.zty)) # O(pq)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q)    # O(q^2)\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, obs.storage_q) # O(q^3)\n",
    "    # l2 norm of residual vector\n",
    "    copy!(obs.storage_p, obs.xty)\n",
    "    rtr  = obs.yty +\n",
    "        dot(β, BLAS.gemv!('N', T(1), obs.xtx, β, T(-2), obs.storage_p))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2π) + (n - q) * log(σ²) # constant term\n",
    "    @inbounds for j in 1:q\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (rtr - qf) / σ² \n",
    "    logl /= -2\n",
    "    ###################\n",
    "    # Evaluate gradient\n",
    "    ###################    \n",
    "    if needgrad\n",
    "        # TODO: fill ∇β, ∇L, ∇σ² by gradients\n",
    "        sleep(1e-3) # pretend this step takes 1ms\n",
    "    end    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/gradient evaluator here. First generate the same data set as in HW2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: Random not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: Random not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[2]:1"
     ]
    }
   ],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Σ)).L)\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
