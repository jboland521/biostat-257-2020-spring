{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIOSTAT 257 Homework 2\n",
    "\n",
    "Consider a linear mixed effects model\n",
    "\n",
    "$$Y_i = X_i\\beta + Z_i\\gamma + \\epsilon_i, \\quad i = 1,\\ldots,n$$\n",
    "\n",
    "where\n",
    "\n",
    "- $Y_i \\in \\mathbb{R}^{n_i}$ is the reponse vector of the $i$-th individual,\n",
    "- $X_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effect predictor matrix of  $i$-th individual,\n",
    "- $Z_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effect predictor matrix of  $i$-th individual, \n",
    "- $\\epsilon_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(0_{n_i}, \\sigma^2 I_{n_i})$,\n",
    "- $\\beta \\in \\mathbb{R}^{p}$ are fixed effects, and\n",
    "- $\\gamma \\in \\mathbb{R}^{q}$ are random effects assumed to be $N(0_{q}, \\Sigma_{q \\times q})$ independent of $\\epsilon_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Formula\n",
    "\n",
    "Write down the log-likelihood of the  $i$-th datum  $(Y_i,X_i,Z_i)$  given parameters $(\\beta,\\Sigma,\\sigma^2)$.\n",
    "\n",
    "The marginal distribution of $Y_i \\sim N(X_i \\beta, Z_i \\Sigma Z_i^T + \\sigma^2 I_{n_i})$\n",
    "\n",
    "$$\\ell(\\beta,\\Sigma,\\sigma^2) = -\\frac{n_i}{2}\\text{log}(2\\pi) - \\frac{1}{2}\\text{log}|Z_i \\Sigma Z_i^T + \\sigma^2 I_{n_i}| - \\frac{1}{2}(Y_i - X_i \\beta)^T(Z_i \\Sigma Z_i^T + \\sigma^2 I_{n_i})^{-1}(Y_i - X_i \\beta)$$\n",
    "\n",
    "The most computationally challenging terms will be the log determinant and the matrix inversion. First we know that $\\Sigma = L L'$. We can write \n",
    "\n",
    "$$Z\\Sigma Z^T = Z L L^T Z^T = (ZL)(ZL)^T = RR^T$$\n",
    "\n",
    "We can use Woodbury to rewrite the covariance matrix as:\n",
    "\n",
    "$$(RR^T + \\sigma^2 I_{n_i})^{-1} = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}R\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg)^{-1}R^T.$$\n",
    "\n",
    "Then, the quadratic form then becomes: \n",
    "\n",
    "$$\\frac{1}{\\sigma^2}(y-X\\beta)^T(y-X\\beta) -\\frac{1}{\\sigma^4}(y-X\\beta)^TR\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg)^{-1}R^T(y-X\\beta)$$\n",
    "\n",
    "where if we let $C = R^T(y-X\\beta) = L^TZ^T(y-X\\beta)$, this then becomes:\n",
    "\n",
    "$$\\frac{1}{\\sigma^2}(y-X\\beta)^T(y-X\\beta) -\\frac{1}{\\sigma^4}C^T\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg)^{-1}C$$\n",
    "\n",
    "$$I + \\frac{1}{\\sigma^2}R^TR = MM^T.$$\n",
    "\n",
    "Which leads us to: \n",
    "\n",
    "$$(RR^T + \\sigma^2 I_{n_i})^{-1} = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}R\\Bigg(MM^T\\Bigg)^{-1}R^T = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}RM^{-T}M^{-1}R^T$$\n",
    "\n",
    "\n",
    "$$(RR^T + \\sigma^2 I_{n_i})^{-1} = \\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}Q^TQ$$\n",
    "\n",
    "such that $M^{-1}R^T = Q$. If we let $e = y - X \\beta$, then we can write the quadratic form as:\n",
    "\n",
    "$$e^T(\\frac{1}{\\sigma^2}I -\\frac{1}{\\sigma^4}Q^TQ)e = \\frac{1}{\\sigma^2}e^Te - \\frac{1}{\\sigma^4} e^TQ^TQe$$\n",
    "\n",
    "The other difficult term to work with is \n",
    "\n",
    "$$\\text{det}(\\sigma^2I + Z\\Sigma Z^T) = \\text{det}(\\sigma^2I)\\text{det}\\Bigg(I + \\frac{1}{\\sigma^2}R^TR\\Bigg) = (\\sigma^2)^n\\text{det}(MM^T)$$\n",
    "\n",
    "Thus we can re-write the log-likelihood as\n",
    "\n",
    "$$\\ell(\\beta,\\Sigma,\\sigma^2) = -\\frac{n_i}{2}\\text{log}(2\\pi) - \\frac{1}{2}log((\\sigma^2)^n\\text{det}(MM^T)) - \\frac{1}{2\\sigma^2}e^Te + \\frac{1}{2\\sigma^4} e^TQ^TQe$$\n",
    "\n",
    "$$\\ell(\\beta,\\Sigma,\\sigma^2) = -\\frac{n_i}{2}\\text{log}(2\\pi) - \\frac{n_i}{2}log(\\sigma^2) -\\frac{1}{2}log(\\text{det}(MM^T)) - \\frac{1}{2\\sigma^2}e^Te + \\frac{1}{2\\sigma^4} e^TQ^TQe$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Start-up Code\n",
    "\n",
    "Use the following template to define a type `LmmObs` that holds an LMM datum $(y_i,X_i,Z_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Distributions, LinearAlgebra, Random, SparseArrays, InteractiveUtils\n",
    "\n",
    "# define a type that holds LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y :: Vector{T}\n",
    "    X :: Matrix{T}\n",
    "    Z :: Matrix{T}\n",
    "    # working arrays\n",
    "    # whatever intermediate arrays you may want to pre-allocate\n",
    "    res         :: Vector{T}\n",
    "    storage_q   :: Vector{T}\n",
    "    storage_q2  :: Vector{T}\n",
    "    ztz         :: Matrix{T}\n",
    "    storage_qq  :: Matrix{T}\n",
    "    storage_qq2 :: Matrix{T}\n",
    "end\n",
    "\n",
    "# constructor\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}) where T <: AbstractFloat\n",
    "    res         = similar(y)\n",
    "    storage_q   = Vector{T}(undef, size(Z, 2))\n",
    "    storage_q2  = Vector{T}(undef, size(Z, 2))\n",
    "    ztz         = transpose(Z) * Z\n",
    "    storage_qq  = similar(ztz)\n",
    "    storage_qq2 = similar(ztz)\n",
    "    LmmObs(y, X, Z, res, storage_q, storage_q2, ztz, storage_qq, storage_qq2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, with interface `logl!(obs, β, L, σ²)` that evaluates the log-likelihood of the $i$-th datum. Here `L` is the lower triangular Cholesky factor from the Cholesky decomposition `Σ=LL'`. Make your code efficient in the $n_i≫q$ case. Think the intensive longitudinal measurement setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl! (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logl!(\n",
    "        obs :: LmmObs{T}, \n",
    "        β   :: Vector{T}, \n",
    "        L   :: Matrix{T}, \n",
    "        σ²  :: T) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2) \n",
    "    ## Calculate y - Xβ\n",
    "    mul!(obs.res, obs.X, β)\n",
    "    axpy!(-1, obs.y, obs.res)\n",
    "    \n",
    "    ## Start calculating (I + (1/σ^2)R^tR)\n",
    "    mul!(obs.storage_qq, obs.ztz, L)\n",
    "    mul!(obs.storage_qq2, L', obs.storage_qq)\n",
    "    mul!(obs.ztz, obs.storage_qq2, (1/σ²))\n",
    "    for i = 1:q\n",
    "        obs.ztz[i, i] += 1\n",
    "    end\n",
    "    \n",
    "    ## Cholesky Decomposition of (I + (1/σ^2)R^tR)\n",
    "    M = cholesky!(Symmetric(obs.ztz))\n",
    "\n",
    "    ## M⁻¹ Lᵀ Zᵀ (y - Xβ)\n",
    "    mul!(obs.storage_q, obs.Z', obs.res)\n",
    "    mul!(obs.storage_q2, L', obs.storage_q)\n",
    "    ldiv!(obs.storage_q, M, obs.storage_q2)\n",
    "    \n",
    "    return -n / 2 * log(2 * π) - n / 2 * log(σ²) - 1 / 2 * logdet(M) - \n",
    "        1/ (2 * σ²) * dot(obs.res, obs.res) + \n",
    "        1 / (2 * (σ²)^2) * dot(obs.storage_q2, obs.storage_q)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: This function shouldn't be very long. Mine, obeying 80-character rule, is 25 lines. If you find yourself writing very long code, you're on the wrong track. Think about algorithm first then use BLAS functions to reduce memory allocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Correctness\n",
    "\n",
    "Compare your result (both accuracy and timing) to the Distributions.jl package using following data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs{Float64}([5.739048710854997, 5.705395720270055, 2.7368899643050355, 1.4201223592870755, -0.2099433929180451, 3.5886971824690486, -1.3778538474575956, -0.08406026821055246, -2.208007878450787, 1.309558511583542  …  1.2947876180172684, -1.9701265304395086, -2.040383092851745, -1.4590296825658675, 0.18616271231054726, 1.0681247149968018, 2.2292080864625254, 1.1952385354603545, 1.1310626949609701, -0.43507816286713785], [1.0 -2.506566300781151 … 0.5863780184080776 1.1092991040518192; 1.0 -0.974090320735282 … 1.4143507320583761 0.45608259198567447; … ; 1.0 -1.0076371084863895 … -1.3241972696483915 1.4547609424344008; 1.0 0.38036793320364776 … -0.5857507269707397 1.796804266836504], [1.0 -0.6380567326757537 1.4738982136806946; 1.0 -2.0711110232845926 0.21422658785510312; … ; 1.0 0.5917731507133951 -0.9163364468263059; 1.0 0.9463732120394507 -0.325860403600768], [2.49199834e-316, 2.121995791e-314, 0.0, 2.49199953e-316, 2.121995791e-314, 2.1191752e-316, 2.4920007e-316, 2.121995791e-314, 2.07203345e-316, 2.4920019e-316  …  2.4927849e-316, 2.121995791e-314, 0.0, 2.4927861e-316, 2.121995791e-314, 2.4926774e-316, 2.49278727e-316, 2.121995791e-314, 2.49277857e-316, 2.49278845e-316], [6.92068750957984e-310, 6.9206792829149e-310, 6.9206792712004e-310], [6.9206875096241e-310, 6.9206512007058e-310, 6.9206792783786e-310], [2000.0 -11.203585688587854 -23.356385339139603; -11.203585688587854 1972.7426082447305 27.30329698263215; -23.356385339139603 27.30329698263215 2034.2034944863572], [2.570299411036706e184 3.305255183292498e179 3.797449719831574e175; 2.3630821517683885e180 6.034691920517918e174 1.398384862755237e-76; 7.629295249928557e169 2.957142669318295e-32 6.92067927283834e-310], [3.838195170778782e151 3.8098506874642707e180 4.7393685797039125e97; 3.9825729613459225e246 1.4152940241145922e161 4.18774641524896e-62; 4.50622044154305e-144 6.007368992179743e-67 1.1176310872122545e261])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form an LmmObs object\n",
    "obs = LmmObs(y, X, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3247.4568580638297"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl!(obs, β, Matrix(cholesky(Σ).L), σ²) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3247.456858063827"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "μ  = X * β\n",
    "Ω  = Z * Σ * transpose(Z) +  σ² * I\n",
    "mvn = MvNormal(μ, Symmetric(Ω)) # MVN(μ, Σ)\n",
    "logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert logl!(obs, β, Matrix(cholesky(Σ).L), σ²) ≈ logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.55 MiB\n",
       "  allocs estimate:  5\n",
       "  --------------\n",
       "  minimum time:     7.384 ms (0.00% GC)\n",
       "  median time:      7.941 ms (0.00% GC)\n",
       "  mean time:        17.586 ms (4.79% GC)\n",
       "  maximum time:     39.075 ms (1.37% GC)\n",
       "  --------------\n",
       "  samples:          285\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm1 = @benchmark logpdf($mvn, $y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  272 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     7.400 μs (0.00% GC)\n",
       "  median time:      12.350 μs (0.00% GC)\n",
       "  mean time:        13.879 μs (0.00% GC)\n",
       "  maximum time:     46.533 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = Matrix(cholesky(Σ).L)\n",
    "bm2 = @benchmark logl!($obs, $β, $L, $σ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.289635627530362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(median(bm1).time / median(bm2).time / 1000 * 30, 0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.734375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(30 - median(bm2).memory / 1024, 0, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
